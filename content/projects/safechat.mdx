---
title: "SafeChat"
blurb: "A zero-trust quorum that helps prevent undesired interactions."
repo: "https://github.com/hapticPaper/safechat"
previewImage: "https://raw.githubusercontent.com/hapticPaper/safechat/master/demo.png"
previewAlt: "SafeChat demo screenshot"
date: "2026-01-19"
tags:
  - "Security"
  - "Agentic pipelines"
  - "System design"
---

SafeChat explores a simple question: how do you put *guardrails* around LLM interactions in a way thatâ€™s actually composable and practical?

The core idea is a quorum-based decision layer that can block or shape outputs based on policy and context.
